{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, TabularDataset, BucketIterator,LabelField\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/babyhandzzz/Desktop/ELEPH@NT/Datasets/clean_IMDB.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "tokenize = lambda x: x.split()\n",
    "TEXT = Field(sequential=True, tokenize=tokenize,batch_first=True)\n",
    "LABEL = LabelField(dtype=torch.float,batch_first=True)\n",
    "fields = [('text', TEXT), ('label',LABEL)]\n",
    "training_data=TabularDataset(path=path,format='csv',fields = fields, skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "SEED=2020\n",
    "train_data, valid_data = training_data.split(split_ratio=0.7, random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize words GloVe\n",
    "TEXT.build_vocab(train_data,min_freq=3,vectors=\"glove.6B.100d\")  \n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator = BucketIterator.splits((train_data, valid_data), batch_size = 32,\n",
    "sort_key = lambda x: len(x.text),sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\tdef __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\n",
    "\t\tsuper(LSTMClassifier, self).__init__()\n",
    "\t\t\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.output_size = output_size\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.vocab_size = vocab_size\n",
    "\t\tself.embedding_length = embedding_length\n",
    "\t\t\n",
    "\t\tself.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
    "\t\tself.word_embeddings.weight = nn.Parameter(weights, requires_grad=False)\n",
    "\t\tself.lstm = nn.LSTM(embedding_length, hidden_size)\n",
    "\t\tself.label = nn.Linear(hidden_size, output_size)\n",
    "\t\t\n",
    "\tdef forward(self, input_embedding, batch_size=None):\n",
    "\t\n",
    "\t\tinput_ = self.word_embeddings(input_embedding) \n",
    "\t\tinput_ = input_.permute(1, 0, 2)\n",
    "\t\tif batch_size is None:\n",
    "\t\t\th_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size)) \n",
    "\t\t\tc_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size))\n",
    "\t\telse:\n",
    "\t\t\th_0 = Variable(torch.zeros(1, batch_size, self.hidden_size))\n",
    "\t\t\tc_0 = Variable(torch.zeros(1, batch_size, self.hidden_size))\n",
    "\t\toutput, (final_hidden_state, final_cell_state) = self.lstm(input_, (h_0, c_0))\n",
    "\t\tfinal_output = self.label(final_hidden_state[-1]) \t\t\n",
    "\t\treturn final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "output_size = 1\n",
    "hidden_size = 150\n",
    "vocab_size = len(TEXT.vocab)\n",
    "embedding_length = 100\n",
    "word_embeddings = TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(batch_size, output_size, hidden_size, vocab_size, embedding_length, word_embeddings)\n",
    "loss_fn = nn.BCELoss()\n",
    "optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.6933239698410034\n0.6928998827934265\n0.6946552991867065\n0.6910000443458557\n0.6919717788696289\n0.6925653219223022\n0.6938671469688416\n0.6881396174430847\n0.6871300339698792\n0.6969411373138428\n0.68184894323349\n0.6823946833610535\n0.6900270581245422\n0.6696925163269043\n0.679523229598999\n0.6788899302482605\n0.666327714920044\n0.6704390645027161\n0.7030359506607056\n0.719089686870575\n0.7318813800811768\n0.7316553592681885\n0.7288674712181091\n0.6906354427337646\n0.6850621700286865\n0.6783450841903687\n0.6935259103775024\n0.674932062625885\n0.6944950819015503\n0.6963032484054565\n0.6707750558853149\n0.6902047395706177\n0.6976813077926636\n0.695963978767395\n0.7015758752822876\n0.6983414888381958\n0.680922269821167\n0.6677483916282654\n0.6704552173614502\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-657801c59964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for idx, batch in enumerate(train_iterator):\n",
    "    text = batch.text\n",
    "    target = batch.label\n",
    "    if (text.size()[0] is not 32):\n",
    "            continue\n",
    "    optim.zero_grad()\n",
    "    prediction = model(text)\n",
    "    loss = loss_fn(F.sigmoid(prediction), target)\n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594820555572",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}