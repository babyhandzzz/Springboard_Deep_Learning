{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, TabularDataset, BucketIterator,LabelField\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/babyhandzzz/Desktop/ELEPH@NT/Datasets/clean_IMDB.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "tokenize = lambda x: x.split()\n",
    "TEXT = Field(sequential=True, tokenize=tokenize,batch_first=True)\n",
    "LABEL = LabelField(dtype=torch.int,batch_first=True)\n",
    "fields = [('text', TEXT), ('label',LABEL)]\n",
    "training_data=TabularDataset(path=path,format='csv',fields = fields, skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "SEED=2020\n",
    "train_data, valid_data = training_data.split(split_ratio=0.7, random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize words GloVe\n",
    "TEXT.build_vocab(train_data,min_freq=3,vectors=\"glove.6B.100d\")  \n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<torchtext.data.field.Field at 0x7fbab17ab810>"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "TEXT.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator = BucketIterator.splits((train_data, valid_data), batch_size = 32,\n",
    "sort_key = lambda x: len(x.text),sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\tdef __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\n",
    "\t\tsuper(LSTMClassifier, self).__init__()\n",
    "\t\t\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.output_size = output_size\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.vocab_size = vocab_size\n",
    "\t\tself.embedding_length = embedding_length\n",
    "\t\t\n",
    "\t\tself.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
    "\t\tself.word_embeddings.weight = nn.Parameter(weights, requires_grad=False)\n",
    "\t\tself.lstm = nn.LSTM(embedding_length, hidden_size)\n",
    "\t\tself.label = nn.Linear(hidden_size, output_size)\n",
    "\t\t\n",
    "\tdef forward(self, input_embedding, batch_size=None):\n",
    "\t\n",
    "\t\tinput_ = self.word_embeddings(input_embedding) \n",
    "\t\treturn input_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "output_size = 1\n",
    "hidden_size = 150\n",
    "vocab_size = len(TEXT.vocab)\n",
    "embedding_length = 100\n",
    "word_embeddings = TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(batch_size, output_size, hidden_size, vocab_size, embedding_length, word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[-9.4820e-01,  2.9996e-01, -2.2521e+00,  ...,  9.8973e-01,\n           1.4729e+00,  1.7758e+00],\n         [ 1.0750e-01,  6.0153e-01,  2.2525e-01,  ...,  9.6780e-01,\n          -7.4871e-01, -2.7538e-02],\n         [ 1.4004e-01, -1.0123e+00,  5.8283e-01,  ..., -5.5197e-01,\n          -3.0484e-01,  1.4219e-01],\n         ...,\n         [-3.7835e-01,  9.1582e-01,  6.2399e-01,  ..., -2.1765e+00,\n           4.2013e-01,  5.9320e-01],\n         [ 6.4673e-01,  2.8239e-01, -1.9636e+00,  ..., -6.2310e-02,\n           1.2249e+00, -6.6461e-01],\n         [ 2.4890e-01, -2.4176e-01,  4.3373e-01,  ...,  4.6947e-01,\n           6.6965e-01,  5.4410e-01]],\n\n        [[ 3.9167e-01, -2.3850e-01, -1.0974e+00,  ...,  5.6394e-01,\n           5.6635e-01, -3.1735e-01],\n         [ 1.1163e+00, -4.5154e-01,  1.3764e+00,  ...,  7.1564e-01,\n          -8.4829e-01, -9.3492e-01],\n         [ 1.5986e-01,  4.4215e-01, -7.0887e-01,  ..., -7.2369e-01,\n           9.7959e-01,  1.1549e+00],\n         ...,\n         [ 1.0949e+00,  2.2208e-01, -2.3271e-01,  ..., -4.3983e-01,\n           1.0976e+00, -9.9112e-01],\n         [ 1.8096e-01,  1.4134e+00, -1.1491e-02,  ..., -1.0498e+00,\n          -1.0203e+00, -1.5999e-01],\n         [ 1.2052e+00, -2.8300e-01, -1.1363e+00,  ...,  2.5426e-01,\n          -1.0664e+00,  1.8039e-03]],\n\n        [[-9.4820e-01,  2.9996e-01, -2.2521e+00,  ...,  9.8973e-01,\n           1.4729e+00,  1.7758e+00],\n         [-2.8845e-01,  1.6096e+00,  1.1652e+00,  ..., -1.7070e+00,\n           7.6249e-01, -1.7742e+00],\n         [ 4.6931e-01, -2.7999e+00,  7.1394e-03,  ..., -3.1926e-01,\n           1.7846e+00, -4.4362e-01],\n         ...,\n         [ 7.0560e-01,  2.5031e-01, -1.9649e-01,  ..., -6.3466e-02,\n           6.1596e-01,  9.1810e-01],\n         [ 7.0560e-01,  2.5031e-01, -1.9649e-01,  ..., -6.3466e-02,\n           6.1596e-01,  9.1810e-01],\n         [ 7.0560e-01,  2.5031e-01, -1.9649e-01,  ..., -6.3466e-02,\n           6.1596e-01,  9.1810e-01]],\n\n        ...,\n\n        [[ 2.5211e+00, -4.5747e-01,  8.3617e-01,  ...,  1.9412e-01,\n           1.0916e+00,  2.2939e+00],\n         [ 4.4829e-01,  1.9033e+00, -2.8034e-02,  ...,  1.8016e-01,\n           1.0786e-01,  2.0122e-01],\n         [ 2.2699e-01, -2.1796e+00,  1.3174e+00,  ...,  8.9874e-01,\n           6.9352e-02,  2.6926e-01],\n         ...,\n         [ 7.0560e-01,  2.5031e-01, -1.9649e-01,  ..., -6.3466e-02,\n           6.1596e-01,  9.1810e-01],\n         [ 7.0560e-01,  2.5031e-01, -1.9649e-01,  ..., -6.3466e-02,\n           6.1596e-01,  9.1810e-01],\n         [ 7.0560e-01,  2.5031e-01, -1.9649e-01,  ..., -6.3466e-02,\n           6.1596e-01,  9.1810e-01]],\n\n        [[ 1.5986e-01,  4.4215e-01, -7.0887e-01,  ..., -7.2369e-01,\n           9.7959e-01,  1.1549e+00],\n         [-6.6746e-01,  3.9487e-01,  1.2218e+00,  ...,  3.1561e-01,\n          -1.6596e+00, -2.9893e-01],\n         [ 1.0520e+00,  2.0665e-01, -6.5295e-01,  ...,  5.3548e-02,\n           1.5885e-01, -1.0056e+00],\n         ...,\n         [ 7.0560e-01,  2.5031e-01, -1.9649e-01,  ..., -6.3466e-02,\n           6.1596e-01,  9.1810e-01],\n         [ 7.0560e-01,  2.5031e-01, -1.9649e-01,  ..., -6.3466e-02,\n           6.1596e-01,  9.1810e-01],\n         [ 7.0560e-01,  2.5031e-01, -1.9649e-01,  ..., -6.3466e-02,\n           6.1596e-01,  9.1810e-01]],\n\n        [[-1.1581e-01, -7.4895e-01,  1.2820e+00,  ..., -3.4393e-01,\n           1.2841e+00, -4.5750e-01],\n         [-9.4820e-01,  2.9996e-01, -2.2521e+00,  ...,  9.8973e-01,\n           1.4729e+00,  1.7758e+00],\n         [ 1.0459e+00, -4.2568e-01, -3.2395e+00,  ..., -4.7752e-01,\n           6.3448e-01, -8.8750e-01],\n         ...,\n         [ 7.0560e-01,  2.5031e-01, -1.9649e-01,  ..., -6.3466e-02,\n           6.1596e-01,  9.1810e-01],\n         [ 7.0560e-01,  2.5031e-01, -1.9649e-01,  ..., -6.3466e-02,\n           6.1596e-01,  9.1810e-01],\n         [ 7.0560e-01,  2.5031e-01, -1.9649e-01,  ..., -6.3466e-02,\n           6.1596e-01,  9.1810e-01]]], grad_fn=<EmbeddingBackward>)\n"
    }
   ],
   "source": [
    "for idx, batch in enumerate(train_iterator):\n",
    "    text = batch.text\n",
    "    target = batch.label\n",
    "    prediction = model(text)\n",
    "    print(prediction)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n        ...,\n        [-0.0629, -0.5078, -0.5660,  ...,  0.0900,  0.3337, -0.3578],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594810781555",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}